import requests
import os
from datetime import datetime, timedelta
import pytz

# 1. í™˜ê²½ ë³€ìˆ˜ ì •ë³´
NAVER_ID = os.environ.get('NAVER_CLIENT_ID')
NAVER_SECRET = os.environ.get('NAVER_CLIENT_SECRET')
TG_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')

# [í•¨ìˆ˜] í‚¤ì›Œë“œ ë¡œë“œ
def load_keywords():
    filename = "keywords.txt"
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return [line.strip() for line in f.read().splitlines() if line.strip()]
    return []

# [í•¨ìˆ˜] ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
def get_news(keyword, sort_type):
    query = f'"{keyword}"'
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=30&sort={sort_type}"
    headers = {"X-Naver-Client-Id": NAVER_ID, "X-Naver-Client-Secret": NAVER_SECRET}
    try:
        res = requests.get(url, headers=headers)
        return res.json().get('items', [])
    except:
        return []

# [í•¨ìˆ˜] í…”ë ˆê·¸ë¨ ì „ì†¡
def send_tg(text):
    if not text.strip(): return
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML", "disable_web_page_preview": True}
    requests.post(url, json=payload)

# [í•¨ìˆ˜] ì œëª© ì •í™”
def clean_title(title):
    return title.replace("<b>", "").replace("</b>", "").replace("&quot;", '"').replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">").strip()

# [í•¨ìˆ˜] í•œêµ­ ë‚ ì§œ í¬ë§·
def format_date_kor(date_str):
    try:
        weekday_map = {"Mon": "ì›”", "Tue": "í™”", "Wed": "ìˆ˜", "Thu": "ëª©", "Fri": "ê¸ˆ", "Sat": "í† ", "Sun": "ì¼"}
        dt_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S +0900')
        kor_w = weekday_map.get(dt_obj.strftime('%a'), dt_obj.strftime('%a'))
        return dt_obj.strftime(f'%Y.%m.%d.({kor_w}) %H:%M')
    except:
        return date_str

# --- [ë©”ì¸ ì‹¤í–‰] ---

korea_tz = pytz.timezone('Asia/Seoul')
now_korea = datetime.now(korea_tz)

# ìƒˆë²½ ë°œì†¡ ê¸ˆì§€
if 0 <= now_korea.hour < 6:
    exit()

# ì´í‹€(48ì‹œê°„) ê¸°ì¤€ ì‹œê°„ ê³„ì‚°
two_days_ago = now_korea - timedelta(days=2)

# 1. ê¸°ë¡ íŒŒì¼ ë¡œë“œ ë° ì´í‹€ ì§€ë‚œ ê¸°ë¡ ìë™ ì‚­ì œ
DB_FILE = "sent_links.txt"
valid_records = {} # {ë§í¬: ì €ì¥ë‚ ì§œë¬¸ìì—´}
if os.path.exists(DB_FILE):
    with open(DB_FILE, "r", encoding="utf-8") as f:
        for line in f:
            if "|" in line:
                link, save_date_str = line.strip().split("|")
                try:
                    save_dt = datetime.strptime(save_date_str, '%Y%m%d%H%M')
                    save_dt = korea_tz.localize(save_dt)
                    # ì €ì¥ëœ ì‹œê°„ì´ ì´í‹€ ì´ë‚´ì¸ ê²½ìš°ë§Œ ìœ ì§€
                    if save_dt > two_days_ago:
                        valid_records[link] = save_date_str
                except:
                    continue

KEYWORDS = load_keywords()
all_collected_articles = []
no_news_keywords = [] # ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ëŠ” í‚¤ì›Œë“œ ë³´ê´€í•¨

# 2. í‚¤ì›Œë“œë³„ ìˆ˜ì§‘ ì‹œì‘
for kw in KEYWORDS:
    raw_candidates = get_news(kw, "sim") + get_news(kw, "date")
    current_titles = []
    found_new_for_this_kw = False
    
    for item in raw_candidates:
        link = item['link']
        title = clean_title(item['title'])
        pub_date_raw = item.get('pubDate', '')
        
        # ê¸°ì‚¬ ë°œí–‰ì¼ì´ ì´í‹€ ì´ë‚´ì¸ì§€ í™•ì¸
        try:
            pub_dt = datetime.strptime(pub_date_raw, '%a, %d %b %Y %H:%M:%S +0900')
            pub_dt = korea_tz.localize(pub_dt)
            if pub_dt < two_days_ago:
                continue
        except:
            continue
            
        # ì¤‘ë³µ í™•ì¸
        if link in valid_records:
            continue
            
        # ì œëª© ì¤‘ë³µ(ë„ë°°) ë°©ì§€
        prefix = title[:15]
        if any(prefix in t for t in current_titles):
            continue
        
        current_titles.append(title)
        found_new_for_this_kw = True
        has_kw = 0 if kw.lower() in title.lower() else 1
        
        all_collected_articles.append({
            "kw": kw, "title": title, "link": link,
            "raw_date": pub_dt, "kor_date": format_date_kor(pub_date_raw),
            "priority": has_kw
        })
        # ìƒˆë¡œìš´ ê¸°ë¡ ì¶”ê°€ (í˜„ì¬ ì‹œê°„ ì €ì¥)
        valid_records[link] = now_korea.strftime('%Y%m%d%H%M')

    if not found_new_for_this_kw:
        no_news_keywords.append(kw)

# 3. ê²°ê³¼ ì „ì†¡
# ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ìˆëŠ” ê²½ìš° (20ê°œì”© ë¬¶ìŒ ë°œì†¡)
if all_collected_articles:
    all_collected_articles.sort(key=lambda x: (x['priority'], x['raw_date']), reverse=True)
    all_collected_articles.sort(key=lambda x: x['priority'])
    
    formatted_msgs = []
    for art in all_collected_articles:
        formatted_msgs.append(f"â€¢ <b>[{art['kw']}]</b> {art['title']}\n  ğŸ•’ {art['kor_date']}\n  <a href='{art['link']}'>ê¸°ì‚¬ë³´ê¸°</a>")

    for i in range(0, len(formatted_msgs), 20):
        chunk = formatted_msgs[i:i + 20]
        send_tg("<b>[ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë¦¬í¬íŠ¸]</b>\n\n" + "\n\n".join(chunk))

# 4. ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ëŠ” í‚¤ì›Œë“œ ì•Œë¦¼
if no_news_keywords:
    status_msg = "<b>[ì•Œë¦¼: ìƒˆë¡œìš´ ê¸°ì‚¬ ì—†ìŒ]</b>\n\n"
    status_msg += "\n".join([f"- {k}" for k in no_news_keywords])
    status_msg += "\n\nìœ„ í‚¤ì›Œë“œë“¤ì— ëŒ€í•œ ìµœê·¼ 2ì¼ ë‚´ ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
    send_tg(status_msg)

# 5. ê¸°ë¡ ì €ì¥ (ìœ íš¨í•œ ê¸°ë¡ë§Œ ë‹¤ì‹œ ì“°ê¸°)
with open(DB_FILE, "w", encoding="utf-8") as f:
    for link, date_str in valid_records.items():
        f.write(f"{link}|{date_str}\n")
